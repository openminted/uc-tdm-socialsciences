== Components

=== PDF processing

//Components inside eu.openminted.uc.tdm.socialsciences.io.pdf

[[pdf-conversion]]
==== PDF to XMI conversion
The PDF-to-XMI conversion pipeline can be used to convert a collection of PDF files to XMI format.

===== Usage: command line
This pipeline can be used via calling the main method, like the following:

[source,text]
----
 $ java -jar /PATH/TO/omtd-uc-ss-io-pdf-1.0.1-pdf-xmi-pipeline-standalone.jar [args...]
----

The following arguments have to be provided for the program:

* *-i <path>* path to input PDF documents. This path can either point to a single file or a directory.
* *-o <path>* path to output directory.
* *-lang <value>* Language of input documents. Possible values: *en* or *de*
* *-overwrite* (Optional) Overwrite output flag. If this option is set program will overwrite any existing files in
output directory.
* *-home* Path to application home where required files (e.g. dictionary files) are located. You can download the
dictionary files from https://github.com/openminted/uc-tdm-socialsciences/releases[here] (ss-io-dictionaries.zip).
* *-converter* (Optional) the converter to be used for extracting text from PDF documents. Possible values: *cermine* or *pdfx*

===== Usage: java
Add the following dependency to your pom file:

[source,xml]
----
<dependency>
    <groupId>eu.openminted.uc.socialsciences</groupId>
    <artifactId>omtd-uc-ss-io-pdf</artifactId>
</dependency>
----

Create an example method like the following:

[source,java]
----
import eu.openminted.uc.socialsciences.io.pdf.PdfToXmiPipeline;

public class PipelineTest
{
    public void runPipelineExample()
    {
        PdfToXmiPipeline pipeline = new PdfToXmiPipeline();
        pipeline.setInput("my/input/directory");
        pipeline.setOutput("my/output/directory");
        pipeline.setLanguage(PdfxXmlToXmiConverter.LANGUAGE_CODE_EN);
        pipeline.setHomePath("my/dictionary/files/directory");
        pipeline.setConverter(PdfToXmiPipeline.CONVERTER_CERMINE); //default is CERMINE
        pipeline.setOverwriteOutput(true); //default is false
        pipeline.run();
    }
}
----

NOTE: The `language` parameter is required to correctly post-process the converted text files (e.g. remove hyphenations inside
words that are split into two lines). This attribute will also be stored in the output XMI files so it can be used
in subsequent text analysis components (e.g. named entity recognition).

NOTE: Currently *pdfx* PDF-to-XML converter can only convert files smaller than 5 MB and containing less than 100 pages. This
limit is enforced by the PDFX service which is used internally to convert PDF documents to XML format.

==== PDF to PDFX-XML conversion
The `PdfxXmlCreator` class can be used to convert a collection of PDF files to PDFX XML format
(http://pdfx.cs.man.ac.uk/static/article-schema.xsd[schema]). This class is used internally by PDF-to-XMI converter
component. This component can be used via calling the main method, like the following:

[source,text]
----
 $ java -cp /PATH/TO/omtd-uc-ss-io-pdf-1.0.1-pdf-xmi-pipeline-standalone.jar
        eu.openminted.uc.socialsciences.io.pdf.pdfx.PdfxXmlCreator [args...]
----

The following arguments have to be provided for the program:

* *-i <path>* path to input PDF documents. This path can either point to a single file or a directory.
* *-o <path>* path to output directory.
* *-overwrite* (Optional) Overwrite output flag. If this option is set program will overwrite any existing files in
output directory.

==== PDFX-XML to XMI conversion
The `PdfxXmlToXmiConverter` class can be used to convert a collection of PDFX XML documents to XMI format. This class is
used internally by PDF-to-XMI converter component. This component can be used via calling the main method, like the
following:

[source,text]
----
 $ java -cp /PATH/TO/omtd-uc-ss-io-pdf-1.0.1-pdf-xmi-pipeline-standalone.jar
        eu.openminted.uc.socialsciences.io.pdf.pdfx.PdfxXmlToXmiConverter [args...]
----

The following arguments have to be provided for the program:

* *-i <path>* path to input directory containing pdfx XML files
* *-o <path>* path to output directory to save converted XMI files
* *-overwrite* (Optional) Overwrite output flag. If this option is set program will overwrite any existing files in
output directory.
* *-lang* language of input documents.
* *-home* Path to application home where required files (e.g. dictionary files) are located

=== Named Entity Recognition
//Components inside eu.openminted.uc.tdm.socialsciences.ner
With this module, you can perform Named Entity Recognition (NER) on your data.

You can:

* input some annotated data to train your own NER model
* apply a trained NER model to new, un-annotated data
* evaluate the performance of any NER model

Training your own model is optional, you might also already have a pre-trained model and use that, or use a model
provided by third parties (e.g. Stanford website).

==== Training your own NER model
To train your own NER model, you will need annotated training data.
The training data has to be in TSV format with one token per line, each sentence separated by a blank line,
with the tokens in the first column and annotations in the second column.

===== Preparing training data
If your training data is in binary CAS format (e.g. exported from WebAnno), you can use the
`BinaryCasToStanfordTsvConverter` to perform the conversion.

*Usage:*

[source,text]
----
 $ java -cp /PATH/TO/omtd-uc-ss-module-ner-1.0.1-ss-ner-standalone.jar
        eu.openminted.uc.socialsciences.ner.util.BinaryCasToTsvConverter [args...]
----

The following arguments have to be provided for the program:

* *-i <path>* path to input documents containing annotations in binary CAS format. This path can either point to a
single file or a directory.
* *-o <path>* (optional) path of output file. Default: ./stanfordTrain.tsv
* *-subtypes <value>* [optional] useSubTypes flag. If set, value and modifier of an annotation will be merged to
create more fine-grained classes.

To see the difference the setting of the `-subtypes` flag makes, consider the following excerpt from a training data
file. In the first case, the flag is set:

[source,text]
----
 by	O
 the	O
 Communist	B-ORGpar
 Party	I-ORGpar
 .	O

 For	O
 instance	O
 ,	O
 researchers	O
 at	O
 the	O
 Institute	B-ORGsci
 of	I-ORGsci
 Economics	I-ORGsci
----

This results in different labels for the two entities that are different kinds of organizations (`ORG`).
Whereas in the second case, the flag has not been set:

[source,text]
----
 by	O
 the	O
 Communist	B-ORG
 Party	I-ORG
 .	O

 For	O
 instance	O
 ,	O
 researchers	O
 at	O
 the	O
 Institute	B-ORG
 of	I-ORG
 Economics	I-ORG
----

Here, both are labeled with the same coarse class 'organization' (`ORG`). Thus, setting the `-subtypes` flag allows to
differentiate sub-types of annotations, but mind that this means an increase in the number of classes for training.

===== Model training
You can use the `StanfordNERTrainer` class to train a new NER model with training data.
You will have to provide a file containing the training properties. 

IMPORTANT: Training might require a lot of memory (RAM).
How much is needed is highly dependent on the number and type of features, on the amount of training data and on the
number of different class labels in the training data.

*Usage:*

[source,text]
----
 $ java -cp /PATH/TO/omtd-uc-ss-module-ner-1.0.1-ss-ner-standalone.jar
        eu.openminted.uc.socialsciences.ner.train.StanfordNERTrainer [args...]
----

The following arguments have to be provided for the program:

* *-i <path>* path to file with training data in .tsv format
* *-o <path>* (optional) path of output file for the serialized model. Default: ./omtd-ner-model.ser.gz
* *-t <value>* path to the training properties file

The file containing the parameters for training has to be in properties format, i.e. one parameter per line in
key-value-pairs like this:

[source,text]
----
 parameter = value
----

You can find detailed descriptions of available training parameters in the FAQ of the Stanford CoreNLP NER:
http://nlp.stanford.edu/software/crf-faq.html

Mind that it is in general possible to set paths to training file(s) and model output file also in the training
properties file, but these values will be overridden.

==== Apply a NER model to un-annotated data
With the `Pipeline` class, you can input un-labeled data and apply a NER model to it, such that the output will contain
labels for all recognized Named Entities.

Input data has to be in XMI (UIMA) format, so if you want to label text from PDF, convert them first
(see <<pdf-conversion,PDF to XMI conversion>>).
You can provide the path to a model in case you pre-trained a model on your own data yourself. 
You can also specify to use one of the pre-trained models that are available (but mind that those models are mostly
trained on newswire text, so if you apply those models to a different domain, the results may have not the quality
you expect).

*Usage:*

[source,text]
----
 $ java -cp /PATH/TO/omtd-uc-ss-module-ner-1.0.1-ss-ner-standalone.jar
        eu.openminted.uc.socialsciences.ner.Pipeline [args...]
----

The following arguments have to be provided for the program:

* *-i <path>* path to input data to be labeled. Can also be a pattern for matching files in a directory, e.g. ./****/*.xmi
* *-o <path>* path to output directory.
* *-standardModel* (optional) Use standard stanford model flag. If this flag is set, standard Stanford models will
be used instead of a custom model.

The results will be written again to XMI files, containing the annotations produced by the Named Entity Recognizer.
Example:

 <NamedEntity:LOC xmi:id="46865" sofa="46711" begin="7014" end="7027" value="LOC" />

==== Evaluate the performance of NER model
We also provide a means to evaluate the results of NER. Use `PerformanceMeasure` for evaluation.
You will need gold data, i.e. manually annotated data with the correct NE labels. 
And of course you will need the prediction data, i.e. documents annotated with the NER. 
Both have to be in XMI format again.

*Usage:*

[source,text]
----
 $ java -cp /PATH/TO/omtd-uc-ss-module-ner-1.0.1-ss-ner-standalone.jar
        eu.openminted.uc.socialsciences.ner.eval.PerformanceMeasure [args...]
----

The following arguments have to be provided for the program:

* *-iGold <path>* path to gold data with correct labels. Can also be a pattern for matching files in a directory,
e.g. ./****/*.xmi
* *-iPred <path>* path to prediction data, i.e. labeled by an algorithm. Can also be a pattern for matching files
in a directory, e.g. ./****/*.xmi
* *-strictId* (optional) If set, for each Gold-document there should be a Prediction-document in the prediction
set with identical documentId (cf. documentId attribute in xmi file). If this requirement is not satisfied,
program will not work properly.
* *-v* (optional) verbose output flag. If this flag is set, output will contain comprehensive information about
tags found in gold and prediction sets.

The program will output agreement scores as well as precision and recall. The output will look similar to this:

[source,text]
----
Calculating agreement scores for doc [5]
Agreement scores on file [5]
	-	Alpha for category OTHevt: -0.000365
	-	Alpha for category LOC: 0.539081
	-	Alpha for category ORGsci: 0.555925
	-	Alpha for category PERind: 0.641172
	-	Alpha for category OTHmed: 1.000000
	-	Alpha for category ORGoth: 0.817166
	-	Alpha for category OTHoff: -0.000134
	-	Alpha for category SUBthe: -0.000594
	-	Alpha for category ORGgov: 1.000000
	-	Alpha for category SUBres: 1.000000
	Overall Alpha: 0.691863

Calculating precision/recall scores for doc [5]
FMeasure scores
	Overall precision: 0.601852
	Overall recall: 0.970149
	Overall F-Measure: 0.742857
----

For calculating the agreement between the predicted annotations and the gold annotations, DKPro Statistics
(https://dkpro.github.io/dkpro-statistics/) library is used. For detailed information about computation of the agreement
scores you can refer to the tutorial (https://dkpro.github.io/dkpro-statistics/inter-rater-agreement-tutorial.pdf)
provided in the DKPro Statistics project.

For calculating the precision and recall, the gold and predicted documents are converted to BIO format annotation.
Each token slot with named entity annotation (either B or I) is used to count the number of true positive, false positive, and
false negative instances.


////
// The following documentation is largely outdated after the refactorings for 1.0.1 and is kept
// here only for historic reference.

=== Variable mention detection and dismbiguation
With this module, you can perform variable mention detection on your data. This module can be used to detect whether
 a sentence from an  article contains a mention of a variable from one of the social sciences studies. The input documents 
 to this module contain one or more sentences from an article and the module output indicates whether a variable is 
 mentioned in the given sentences, and if so the output also contains the id of the mentioned variable.
 
==== Detection and disambiguation pipeline
The class `eu.openminted.uc.socialsciences.variabledetection.DetectionDisambiguationPipeline` can be used to detect
sentences containing variable mentions and link them to the corresponding variable mention. The pipeline can work with
corpus in XML format. If the input documents are in a different format, a different reader should replace the default
`XmlCorpusAllDocsReader` used in this pipeline. The variable mentions detected inside the text will be annotated with the
UIMA type `VariableMention` which is defined in `eu.openminted.uc.socialsciences.annotation.VariableMention`.

The pipeline uses several different lexical features. If you want to enable the features that use external resources
such as WordNet or TheSoz, then please read the following instructions to correctly configure these resources.

===== DKPRO_HOME environment variable
Before continuing, please make sure that you have set up an environment variable `DKPRO_HOME` either system-wide or
 per-project in the Eclipse run configuration (or your chosen IDE). The variable should point to a (possibly yet empty)
 directory which is intended to store any sort of resources which are to be used by any DKPro component.

===== Configuring WordNet
Download WordNet version 3.0 from https://wordnet.princeton.edu/wordnet/download/current-version/[here]
 (download http://wordnetcode.princeton.edu/3.0/WordNet-3.0.tar.gz[tar-gzipped]
 or http://wordnetcode.princeton.edu/3.0/WordNet-3.0.tar.bz2[tar-bzip2'ed]).

After the download has finished, unzip the package and copy the `dict/` directory to
 `$DKPRO_HOME/LexSemResources/Wordnet/`.

Download the Wordnet properties file
 `uc-tdm-socialsciences/src/test/resources/installation/wordnet_properties.xml`
 (https://raw.githubusercontent.com/openminted/uc-tdm-socialsciences/master/ss-variable-detection/src/test/resources/installation/wordnet_properties.xml[download])
 and place it under
 `$DKPRO_HOME/LexSemResources/Wordnet/`. Adjust the value of the `param` element with name `dictionary_path` so it
 contains the absolute path to the dict directory.

Create a directory named `de.tudarmstadt.ukp.dkpro.lexsemresource.core.ResourceFactory` under `$DKPRO_HOME`. Download the
 resources file `uc-tdm-socialsciences/src/test/resources/installation/resources.xml`
 (https://raw.githubusercontent.com/openminted/uc-tdm-socialsciences/master/ss-variable-detection/src/test/resources/installation/resources.xml[download])
 and place it under
 this directory.

===== Configuring TheSoz
This section assumes that you have performed the WordNet configuration mentioned in the previous section.

Download TheSoz files from http://lod.gesis.org/download-thesoz.html[here]
(http://lod.gesis.org/thesoz-komplett.xml.gz[gzipped]).

After the download has finished, unzip the package and copy the content files to
`$DKPRO_HOME/LexSemResources/TheSoz/`.

==== Detection pipeline
The class `eu.openminted.uc.socialsciences.variabledetection.detection.LoadAndApplyPipeline` can be used to only detect
sentences containing variable mentions. The pipeline can work with corpus in XML format. If the input documents are in
a different format, a different reader should replace the default `XmlCorpusAllDocsReader` used in this pipeline.

This pipeline internally uses the `VariableMentionDetector` component to sentences containing a variable mention. This
component uses a DKPro-TC model to classify sentences. The default model for this component can be found under `/data/models/variable-detection`.
If you wish to train your own sentence classifier model you can
use the `eu.openminted.uc.socialsciences.variabledetection.detection.TrainAndSavePipeline` to do so.

==== Disambiguation pipeline
The class `eu.openminted.uc.socialsciences.variabledetection.disambiguation.VariableDisambiguationPipeline` can be used
to link a sentence containing variable mention to its corresponding variable id. The pipeline can work with corpus in
XML format. If the input documents are in a different format, a different reader should replace the default
`XmlCorpusAllDocsReader` used in this pipeline.

This pipeline internally uses the `VariableMentionDetector` component to sentences containing a variable mention. This
component uses a DKPro-TC model to classify sentences. The default model for this component can be found under `/data/models/variable-detection`.
This component also requires a file containing a complete list of variables which can be custom-defined using the
configuration parameter `PARAM_VARIABLE_FILE_LOCATION`.
If you wish to train your own sentence classifier model you can
use the `eu.openminted.uc.socialsciences.variabledetection.detection.TrainAndSavePipeline` to do so.
////