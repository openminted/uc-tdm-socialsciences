== Components

=== PDF processing

//Components inside eu.openminted.uc.tdm.socialsciences.io.pdfx

==== PDF to XMI conversion
The PDF-to-XMI conversion pipeline can be used to convert a collection of PDF files to XMI format. This pipeline can be
used via calling the main method, like the following:

 $ java -jar /PATH/TO/ss-io-pdfx-xml-0.0.1-SNAPSHOT-pdf-xmi-pipeline-standalone.jar [args...]

The following arguments have to be provided for the program:

* *-i <path>* path to input PDF documents. This path can either point to a single file or a directory.
* *-o <path>* path to output directory.
* *-lang <value>* Language of input documents. Possible values: *en* or *de*
* *-overwrite* (Optional) Overwrite output flag. If this option is set program will overwrite any existing files in
output directory.
* *-home* Path to application home where required files (e.g. dictionary files) are located.

The language parameter is required to correctly post-process the converted text files (e.g. remove hyphenations inside
words that are split into two lines). This attribute will also be stored in the output XMI files so it can be used
in subsequent text analysis components (e.g. named entity recognition).

NOTE: Currently PDF-to-XML converter can only convert files smaller than 5 MB and containing less than 100 pages. This
limit is enforced by the PDFX service which is used internally to convert PDF documents to XML format.

===== PDF to XML conversion
The PdfxXmlCreator class can be used to convert a collection of PDF files to PDFX XML format
(http://pdfx.cs.man.ac.uk/static/article-schema.xsd[schema]). This class is used internally by PDF-to-XMI converter
component. This component can be used via calling the main method, like the following:

 $ java -cp /PATH/TO/ss-io-pdfx-xml-0.0.1-SNAPSHOT-pdf-xmi-pipeline-standalone.jar
        eu.openminted.uc.socialsciences.io.pdfx.PdfxXmlCreator [args...]

The following arguments have to be provided for the program:

* *-i <path>* path to input PDF documents. This path can either point to a single file or a directory.
* *-o <path>* path to output directory.
* *-overwrite* (Optional) Overwrite output flag. If this option is set program will overwrite any existing files in
output directory.

===== PDFX-XML to XMI conversion
The PdfxXmlToXmiConverter class can be used to convert a collection of PDFX XML documents to XMI format. This class is
used internally by PDF-to-XMI converter component. This component can be used via calling the main method, like the
following:

 $ java -cp /PATH/TO/ss-io-pdfx-xml-0.0.1-SNAPSHOT-pdf-xmi-pipeline-standalone.jar
        eu.openminted.uc.socialsciences.io.pdfx.PdfxXmlToXmiConverter [args...]

The following arguments have to be provided for the program:

* *-i <path>* path to input directory containing pdfx XML files
* *-o <path>* path to output directory to save converted XMI files
* *-overwrite* (Optional) Overwrite output flag. If this option is set program will overwrite any existing files in
output directory.
* *-lang* language of input documents.
* *-home* Path to application home where required files (e.g. dictionary files) are located

=== Named Entity Recognition
//Components inside eu.openminted.uc.tdm.socialsciences.ner
With this module, you can perform Named Entity Recognition (NER) on your own data.

You can:

* input some annotated data to train your own NER model
* apply a trained NER model to new, un-annotated data
* evaluate the performance of any NER model

Training your own model is optional, you might also already have a pre-trained model and use that, or use a model
provided by third parties (e.g. Stanford website).

==== Training your own NER model
To train your own NER model, you will need annotated training data.
The training data has to be in TSV format with one token per line, each sentence separated by a blank line,
with the tokens in the first column and annotations in the second column.

===== Preparing training data
If your training data is in binary CAS format (e.g. exported from WebAnno), you can use the
`BinaryCasToStanfordTsvConverter` to perform the conversion.

*Usage:*

 $ java -cp /PATH/TO/ss-module-ner-0.0.1-SNAPSHOT-ss-ner-standalone.jar
        eu.openminted.uc.socialsciences.ner.helper.BinaryCasToTsvConverter [args...]

The following arguments have to be provided for the program:

* *-i <path>* path to input documents containing annotations in binary CAS format. This path can either point to a
single file or a directory.
* *-o <path>* (optional) path of output file. Default: ./stanfordTrain.tsv
* *-subtypes <value>* [optional] useSubTypes flag. If set, value and modifier of an annotation will be merged to
create more fine-grained classes.

To see the difference the setting of the `-subtypes` flag makes, consider the following excerpt from a training data
file. In the first case, the flag is set:
--------------------------------------
 by	O
 the	O
 Communist	B-ORGpar
 Party	I-ORGpar
 .	O

 For	O
 instance	O
 ,	O
 researchers	O
 at	O
 the	O
 Institute	B-ORGsci
 of	I-ORGsci
 Economics	I-ORGsci
--------------------------------------

This results in different labels for the two entities that are different kinds of organizations (ORG). 
Whereas in the second case, the flag has not been set:

--------------------------------------
 by	O
 the	O
 Communist	B-ORG
 Party	I-ORG
 .	O

 For	O
 instance	O
 ,	O
 researchers	O
 at	O
 the	O
 Institute	B-ORG
 of	I-ORG
 Economics	I-ORG
--------------------------------------

Here, both are labeled with the same coarse class 'organization' (ORG). Thus, setting the `-subtypes` flag allows to
differentiate sub-types of annotations, but mind that this means an increase in the number of classes for training.

===== Model training
You can use the StanfordNERTrainer class to train a new NER model with training data.
You will have to provide a file containing the training properties. 

IMPORTANT: Training might require a lot of memory (RAM).
How much is needed is highly dependent on the number and type of features, on the amount of training data and on the
number of different class labels in the training data.

*Usage:*

 $ java -cp /PATH/TO/ss-module-ner-0.0.1-SNAPSHOT-ss-ner-standalone.jar
        eu.openminted.uc.socialsciences.ner.train.StanfordNERTrainer [args...]

The following arguments have to be provided for the program:

* *-i <path>* path to file with training data in .tsv format
* *-o <path>* (optional) path of output file for the serialized model. Default: ./omtd-ner-model.ser.gz
* *-t <value>* path to the training properties file

The file containing the parameters for training has to be in properties format, i.e. one parameter per line in
key-value-pairs like this:

 parameter = value
 
You can find detailed descriptions of available training parameters in the FAQ of the Stanford CoreNLP NER:
http://nlp.stanford.edu/software/crf-faq.html

Mind that it is in general possible to set paths to training file(s) and model output file also in the training
properties file, but these values will be overriden.

==== Apply a NER model to un-annotated data
With the Pipeline, you can input un-labeled data and apply a NER model to it, such that the output will contain labels
 for all recognized Named Entities.

Input data has to be in XMI (UIMA) format, so if you want to label text from PDF, convert them first
(see <<pdf-conversion,PDF to XMI conversion>>).
You can provide the path to a model in case you pre-trained a model on your own data yourself. 
You can also specify to use one of the pre-trained models that are available (but mind that those models are mostly
trained on newswire text, so if you apply those models to a different domain, the results may have not the quality
you expect).

*Usage:*

 $ java -cp /PATH/TO/ss-module-ner-0.0.1-SNAPSHOT-ss-ner-standalone.jar
        eu.openminted.uc.socialsciences.ner.main.Pipeline [args...]

The following arguments have to be provided for the program:

* *-i <path>* path to input data to be labeled. Can also be a pattern for matching files in a directory, e.g. ./****/*.xmi
* *-o <path>* path to output directory.
* *-standardModel* (optional) Use standard stanford model flag. If this flag is set, standard Stanford models will
be used instead of a custom model.

The results will be written again to XMI files, containing the annotations produced by the Named Entity Recognizer.
Example:

 <NamedEntity:LOC xmi:id="46865" sofa="46711" begin="7014" end="7027" value="LOC" />

==== Evaluate the performance of NER model
We also provide a means to evaluate the results of NER. Use `PerformanceMeasure` for evaluation.
You will need gold data, i.e. manually annotated data with the correct NE labels. 
And of course you will need the prediction data, i.e. documents annotated with the NER. 
Both have to be in XMI format again.

*Usage:*

 $ java -cp /PATH/TO/ss-module-ner-0.0.1-SNAPSHOT-ss-ner-standalone.jar
        eu.openminted.uc.socialsciences.ner.eval.PerformanceMeasure [args...]

The following arguments have to be provided for the program:

* *-iGold <path>* path to gold data with correct labels. Can also be a pattern for matching files in a directory,
e.g. ./****/*.xmi
* *-iPred <path>* path to prediction data, i.e. labeled by an algorithm. Can also be a pattern for matching files
in a directory, e.g. ./****/*.xmi
* *-strictId* (optional) If set, for each Gold-document there should be a Prediction-document in the prediction
set with identical documentId (cf. documentId attribute in xmi file). If this requirement is not satisfied,
program will not work properly.
* *-v" (optional) verbose output flag. If this flag is set, output will contain comprehensive information about
tags found in gold and prediction sets.

The program will output agreement scores as well as precision and recall. The output will look similar to this:

--------------------------------------
Calculating agreement scores for doc [5]
Agreement scores on file [5]
	-	Alpha for category OTHevt: -0.000365
	-	Alpha for category LOC: 0.539081
	-	Alpha for category ORGsci: 0.555925
	-	Alpha for category PERind: 0.641172
	-	Alpha for category OTHmed: 1.000000
	-	Alpha for category ORGoth: 0.817166
	-	Alpha for category OTHoff: -0.000134
	-	Alpha for category SUBthe: -0.000594
	-	Alpha for category ORGgov: 1.000000
	-	Alpha for category SUBres: 1.000000
	Overall Alpha: 0.691863

Calculating precision/recall scores for doc [5]
FMeasure scores
	Overall precision: 0.601852
	Overall recall: 0.970149
	Overall F-Measure: 0.742857
--------------------------------------